{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention - Qutorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math, copy, time\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "seaborn.set_context(context=\"talk\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def smiles2int(drug):\n",
    "\n",
    "    return [VOCAB_LIGAND_ISO[s] for s in drug]\n",
    "\n",
    "def seqs2int(target):\n",
    "\n",
    "    return [VOCAB_PROTEIN[s] for s in target] \n",
    "\"\"\"\n",
    "\n",
    "def rx(phi):\n",
    "    \"\"\"Single-qubit rotation for operator sigmax with angle phi.\n",
    "    -------\n",
    "    result : torch.tensor for operator describing the rotation.\n",
    "    \"\"\"\n",
    "\n",
    "    return torch.cat((torch.cos(phi / 2).unsqueeze(dim = 0), -1j * torch.sin(phi / 2).unsqueeze(dim = 0), \n",
    "                      -1j * torch.sin(phi / 2).unsqueeze(dim = 0), torch.cos(phi / 2).unsqueeze(dim = 0)),dim = 0).reshape(2,-1)\n",
    "    # return torch.tensor([[torch.cos(phi / 2), -1j * torch.sin(phi / 2)],\n",
    "    #              [-1j * torch.sin(phi / 2), torch.cos(phi / 2)]])\n",
    "\n",
    "def ry(phi):\n",
    "    \"\"\"Single-qubit rotation for operator sigmay with angle phi.\n",
    "    -------\n",
    "    result : torch.tensor for operator describing the rotation.\n",
    "    \"\"\"\n",
    "\n",
    "    return torch.cat((torch.cos(phi / 2).unsqueeze(dim = 0), -1 * torch.sin(phi / 2).unsqueeze(dim = 0), \n",
    "                      torch.sin(phi / 2).unsqueeze(dim = 0), torch.cos(phi / 2).unsqueeze(dim = 0)), dim = 0).reshape(2,-1) + 0j\n",
    "    # return torch.tensor([[torch.cos(phi / 2), -torch.sin(phi / 2)],\n",
    "    #              [torch.sin(phi / 2), torch.cos(phi / 2)]])\n",
    "    \n",
    "def rz(phi):\n",
    "    \"\"\"Single-qubit rotation for operator sigmaz with angle phi.\n",
    "    -------\n",
    "    result : torch.tensor for operator describing the rotation.\n",
    "    \"\"\"\n",
    "    return torch.cat((torch.exp(-1j * phi / 2).unsqueeze(dim = 0), torch.zeros(1), \n",
    "                      torch.zeros(1), torch.exp(1j * phi / 2).unsqueeze(dim = 0)), dim = 0).reshape(2,-1)    \n",
    "    # return torch.tensor([[torch.exp(-1j * phi / 2), 0],\n",
    "    #              [0, torch.exp(1j * phi / 2)]])\n",
    "\n",
    "def x_gate():\n",
    "    \"\"\"\n",
    "    Pauli x\n",
    "    \"\"\"\n",
    "    return torch.tensor([[0, 1], [1, 0]]) + 0j\n",
    "\n",
    "def y_gate():\n",
    "    \"\"\"\n",
    "    Pauli y\n",
    "    \"\"\"\n",
    "    return torch.tensor([[0, 0-1j], [0+1j, 0]])\n",
    "\n",
    "def z_gate():\n",
    "    \"\"\"\n",
    "    Pauli z\n",
    "    \"\"\"\n",
    "    return torch.tensor([[1, 0], [0, -1]]) + 0j\n",
    "\n",
    "def cnot():\n",
    "    \"\"\"\n",
    "    torch.tensor representing the CNOT gate.\n",
    "    control=0, target=1\n",
    "    \"\"\"\n",
    "    return torch.tensor([[1, 0, 0, 0],\n",
    "                 [0, 1, 0, 0],\n",
    "                 [0, 0, 0, 1],\n",
    "                 [0, 0, 1, 0]]) + 0j\n",
    "\n",
    "def Hcz():\n",
    "    \"\"\"\n",
    "    controlled z gate for measurement\n",
    "    \"\"\"\n",
    "    return torch.tensor([[1, 0, 0, 0],\n",
    "                 [0, 1, 0, 0],\n",
    "                 [0, 0, 1, 0],\n",
    "                 [0, 0, 0, -1]]) + 0j  \n",
    "\n",
    "def rxx(phi):\n",
    "    \"\"\"\n",
    "    torch.tensor representing the rxx gate with angle phi.\n",
    "    \"\"\"\n",
    "    return torch.kron(rx(phi), rx(phi))\n",
    "\n",
    "def ryy(phi):\n",
    "    \"\"\"\n",
    "    torch.tensor representing the ryy gate with angle phi.\n",
    "    \"\"\"\n",
    "    return torch.kron(ry(phi), ry(phi))\n",
    "\n",
    "def rzz(phi):\n",
    "    \"\"\"\n",
    "    torch.tensor representing the rzz gate with angle phi.\n",
    "    \"\"\"\n",
    "    return torch.kron(rz(phi), rz(phi))\n",
    "\n",
    "\n",
    "def dag(x):\n",
    "    \"\"\"\n",
    "    compute conjugate transpose of input matrix\n",
    "    \"\"\"\n",
    "    x_conj = torch.conj(x)\n",
    "    x_dag = x_conj.permute(1, 0)\n",
    "    return x_dag\n",
    "\n",
    "def multi_kron(x_list):\n",
    "    \"\"\"\n",
    "    kron the data in the list in order\n",
    "    \"\"\"\n",
    "    x_k = torch.ones(1)\n",
    "    for x in x_list:\n",
    "        x_k = torch.kron(x_k, x)\n",
    "    return x_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gate_control(U,N,control,target):\n",
    "    if N<1:\n",
    "        raise ValueError(\"integer N must be larger or equal to 1\")\n",
    "    if control >= N:\n",
    "        raise ValueError(\"control must be integer < integer N\")\n",
    "    if target >= N:\n",
    "        raise ValueError(\"target must be integer < integer N\")\n",
    "    if target==control:\n",
    "        raise ValueError(\"control cannot be equal to target\")\n",
    "        \n",
    "    zero_zero=torch.tensor([[1, 0],[0, 0]]) + 0j\n",
    "    one_one=torch.tensor([[0, 0],[0, 1]]) + 0j\n",
    "    list1=[torch.eye(2)]*N\n",
    "    list2=[torch.eye(2)]*N\n",
    "    list1[control]=zero_zero\n",
    "    list2[control]=one_one\n",
    "    list2[target]=U\n",
    "    \n",
    "    return multi_kron(list1)+multi_kron(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gate_expand_1toN(U, N, target):\n",
    "    \"\"\"\n",
    "    representing a one-qubit gate that act on a system with N qubits.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if N < 1:\n",
    "        raise ValueError(\"integer N must be larger or equal to 1\")\n",
    "\n",
    "    if target >= N:\n",
    "        raise ValueError(\"target must be integer < integer N\")\n",
    "\n",
    "    return multi_kron([torch.eye(2)]* target + [U] + [torch.eye(2)] * (N - target - 1))\n",
    "\n",
    "def gate_expand_2toN(U, N, targets):\n",
    "    \"\"\"\n",
    "    representing a two-qubit gate that act on a system with N qubits.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    if N < 2:\n",
    "        raise ValueError(\"integer N must be larger or equal to 2\")\n",
    "\n",
    "    if targets[1] >= N:\n",
    "        raise ValueError(\"target must be integer < integer N\")\n",
    "\n",
    "    return multi_kron([torch.eye(2)]* targets[0] + [U] + [torch.eye(2)] * (N - targets[1] - 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gate_sequence_product(U_list, n_qubits, left_to_right=True):\n",
    "    \"\"\"\n",
    "    Calculate the overall unitary matrix for a given list of unitary operations.\n",
    "    return: Unitary matrix corresponding to U_list.\n",
    "    \"\"\"\n",
    "\n",
    "    U_overall = torch.eye(2 ** n_qubits, 2 **  n_qubits) + 0j\n",
    "    for U in U_list:\n",
    "        if left_to_right:\n",
    "            U_overall = U @ U_overall\n",
    "        else:\n",
    "            U_overall = U_overall @ U\n",
    "\n",
    "    return U_overall\n",
    "\n",
    "def gate_sequence_product(U_list, n_qubits, left_to_right=True):\n",
    "    \"\"\"\n",
    "    Calculate the overall unitary matrix for a given list of unitary operations.\n",
    "    return: Unitary matrix corresponding to U_list.\n",
    "    \"\"\"\n",
    "\n",
    "    U_overall = torch.eye(2 ** n_qubits, 2 **  n_qubits) + 0j\n",
    "    for U in U_list:\n",
    "        if left_to_right:\n",
    "            U_overall = U @ U_overall\n",
    "        else:\n",
    "            U_overall = U_overall @ U\n",
    "\n",
    "    return U_overall\n",
    "\n",
    "def ptrace(rhoAB, dimA, dimB):\n",
    "    \"\"\"\n",
    "    rhoAB : density matrix\n",
    "    dimA: n_qubits A keep\n",
    "    dimB: n_qubits B trash\n",
    "    \"\"\"\n",
    "    mat_dim_A = 2**dimA\n",
    "    mat_dim_B = 2**dimB\n",
    "\n",
    "    id1 = torch.eye(mat_dim_A, requires_grad=True) + 0.j\n",
    "    id2 = torch.eye(mat_dim_B, requires_grad=True) + 0.j\n",
    "\n",
    "    pout = 0\n",
    "    for i in range(mat_dim_B):\n",
    "        p = torch.kron(id1, id2[i]) @ rhoAB @ torch.kron(id1, id2[i].reshape(mat_dim_B, 1))\n",
    "        pout += p\n",
    "    return pout\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expecval_ZI(state, nqubit, target):\n",
    "    \"\"\"\n",
    "    state为nqubit大小的密度矩阵，target为z门放置位置\n",
    "    \n",
    "    \"\"\"\n",
    "    zgate=z_gate()\n",
    "    H = gate_expand_1toN(zgate, nqubit, target)\n",
    "    expecval = (state @ H).trace() #[-1,1]\n",
    "    expecval_real = (expecval.real + 1) / 2 #[0,1]\n",
    "    \n",
    "    return expecval_real\n",
    "\n",
    "def measure(state, nqubit):\n",
    "    \"\"\"\n",
    "    测量nqubit次期望\n",
    "    \n",
    "    \"\"\"\n",
    "    measure = torch.zeros(nqubit, 1)\n",
    "    for i in range(nqubit):\n",
    "        measure[i] = expecval_ZI(state, nqubit, list(range(nqubit))[i])\n",
    "\n",
    "    return measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(x):\n",
    "    \"\"\"\n",
    "    input: n*n matrix\n",
    "    perform L2 regularization on x, x为complex\n",
    "    \"\"\"\n",
    "    \n",
    "    # if x.norm() != 1 :\n",
    "    #     # print('l2norm:', x.norm())\n",
    "    #     x = x / (x.norm() + 1e-10)\n",
    "    # x = x.type(dtype=torch.complex64)\n",
    "    # return x\n",
    "    # from sklearn.preprocessing import normalize\n",
    "    # xn = normalize(x, norm='l2', axis=0)\n",
    "    with torch.no_grad():\n",
    "        # x = x.squeeze()\n",
    "        if x.norm() != 1:\n",
    "            xd = x.diag()\n",
    "            xds = (xd.sqrt()).unsqueeze(1)\n",
    "            xdsn = xds / (xds.norm() + 1e-12)\n",
    "            xdsn2 = xdsn @ dag(xdsn)\n",
    "            xdsn2 = xdsn2.type(dtype=torch.complex64)\n",
    "        else:\n",
    "            xdsn2 = x.type(dtype=torch.complex64)\n",
    "    # if x.norm() != 1:\n",
    "    #     with torch.no_grad():\n",
    "    #         xd = x.diag()\n",
    "    #         xds = (xd.sqrt()).unsqueeze(1)\n",
    "    #         xdsn = xds / (xds.norm() + 1e-12)\n",
    "    #         xdsn2 = xdsn @ dag(xdsn)\n",
    "    #         xdsn2 = xdsn2.type(dtype=torch.complex64)\n",
    "    # else:\n",
    "    #     xdsn2 = x.type(dtype=torch.complex64)\n",
    "    return xdsn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class init_cir_q(nn.Module):\n",
    "    \"\"\"初始化attn—q\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_qubits=2, \n",
    "                 gain=2 ** 0.5, use_wscale=True, lrmul=1):\n",
    "        super().__init__()\n",
    "\n",
    "        he_std = gain * 5 ** (-0.5)  # He init\n",
    "        if use_wscale:\n",
    "            init_std = 1.0 / lrmul\n",
    "            self.w_mul = he_std * lrmul\n",
    "        else:\n",
    "            init_std = he_std / lrmul\n",
    "            self.w_mul = lrmul\n",
    "        self.weight = nn.Parameter(nn.init.uniform_(torch.empty(n_qubits*3), a=0.0, b=2*np.pi) * init_std)# theta_size=5\n",
    "        \n",
    "        self.n_qubits = n_qubits\n",
    "\n",
    "\n",
    "    def queryQ(self):\n",
    "        w = self.weight * self.w_mul\n",
    "        cir = []\n",
    "        for which_q in range(0, self.n_qubits):\n",
    "            cir.append(gate_expand_1toN(rx(w[which_q*3+0]), self.n_qubits, which_q))\n",
    "            cir.append(gate_expand_1toN(ry(w[which_q*3+1]), self.n_qubits, which_q))        \n",
    "            cir.append(gate_expand_1toN(rz(w[which_q*3+2]), self.n_qubits, which_q))\n",
    "        #for which_q in range(0, self.n_qubits, 2):\n",
    "            #cir.append(gate_expand_1toN(rx(w[0]), self.n_qubits, which_q))\n",
    "            #cir.append(gate_expand_1toN(rx(w[1]), self.n_qubits, which_q + 1))\n",
    "            #cir.append(gate_expand_2toN(ryy(w[2]), self.n_qubits, [which_q, which_q + 1]))\n",
    "            #cir.append(gate_expand_1toN(ry(w[2]), self.n_qubits, which_q))        \n",
    "            #cir.append(gate_expand_1toN(ry(w[3]), self.n_qubits, which_q + 1))\n",
    "            #cir.append(gate_expand_1toN(rz(w[4]), self.n_qubits, which_q))        \n",
    "            #cir.append(gate_expand_1toN(rz(w[5]), self.n_qubits, which_q + 1))\n",
    "        U = gate_sequence_product(cir, self.n_qubits)\n",
    "        return U\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        E_out = self.queryQ()\n",
    "        queryQ_out = E_out@ x @ dag(E_out)\n",
    "        return queryQ_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class init_cir_k(nn.Module):\n",
    "    \"\"\"初始化attn—q\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_qubits=2, \n",
    "                 gain=2 ** 0.5, use_wscale=True, lrmul=1):\n",
    "        super().__init__()\n",
    "\n",
    "        he_std = gain * 5 ** (-0.5)  # He init\n",
    "        if use_wscale:\n",
    "            init_std = 1.0 / lrmul\n",
    "            self.w_mul = he_std * lrmul\n",
    "        else:\n",
    "            init_std = he_std / lrmul\n",
    "            self.w_mul = lrmul\n",
    "        self.weight = nn.Parameter(nn.init.uniform_(torch.empty(n_qubits*3), a=0.0, b=2*np.pi) * init_std)# theta_size=5\n",
    "        \n",
    "        self.n_qubits = n_qubits\n",
    "\n",
    "\n",
    "    def keyQ(self):\n",
    "        w = self.weight * self.w_mul\n",
    "        cir = []\n",
    "        for which_q in range(0, self.n_qubits):\n",
    "            cir.append(gate_expand_1toN(rx(w[which_q*3+0]), self.n_qubits, which_q))\n",
    "            cir.append(gate_expand_1toN(ry(w[which_q*3+1]), self.n_qubits, which_q))        \n",
    "            cir.append(gate_expand_1toN(rz(w[which_q*3+2]), self.n_qubits, which_q))\n",
    "        #for which_q in range(0, self.n_qubits, 2):\n",
    "            #cir.append(gate_expand_1toN(ry(w[0]), self.n_qubits, which_q))\n",
    "            #cir.append(gate_expand_1toN(ry(w[1]), self.n_qubits, which_q + 1))\n",
    "            ##cir.append(gate_expand_2toN(ryy(w[2]), self.n_qubits, [which_q, which_q + 1]))\n",
    "            #cir.append(gate_expand_1toN(rz(w[2]), self.n_qubits, which_q))        \n",
    "            #cir.append(gate_expand_1toN(rz(w[3]), self.n_qubits, which_q + 1))\n",
    "            #cir.append(gate_expand_1toN(rx(w[4]), self.n_qubits, which_q))        \n",
    "            #cir.append(gate_expand_1toN(rx(w[5]), self.n_qubits, which_q + 1))\n",
    "        U = gate_sequence_product(cir, self.n_qubits)\n",
    "        return U\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        E_out = self.keyQ()\n",
    "        keyQ_out = E_out @ x @ dag(E_out)\n",
    "        return keyQ_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class init_cir_v(nn.Module):\n",
    "    \"\"\"初始化attn—q\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_qubits=2, \n",
    "                 gain=2 ** 0.5, use_wscale=True, lrmul=1):\n",
    "        super().__init__()\n",
    "\n",
    "        he_std = gain * 5 ** (-0.5)  # He init\n",
    "        if use_wscale:\n",
    "            init_std = 1.0 / lrmul\n",
    "            self.w_mul = he_std * lrmul\n",
    "        else:\n",
    "            init_std = he_std / lrmul\n",
    "            self.w_mul = lrmul\n",
    "        self.weight = nn.Parameter(nn.init.uniform_(torch.empty(n_qubits*3), a=0.0, b=2*np.pi) * init_std)# theta_size=5\n",
    "        \n",
    "        self.n_qubits = n_qubits\n",
    "\n",
    "\n",
    "    def valueQ(self):\n",
    "        w = self.weight * self.w_mul\n",
    "        cir = []\n",
    "        for which_q in range(0, self.n_qubits):\n",
    "            cir.append(gate_expand_1toN(rx(w[which_q*3+0]), self.n_qubits, which_q))\n",
    "            cir.append(gate_expand_1toN(ry(w[which_q*3+1]), self.n_qubits, which_q))        \n",
    "            cir.append(gate_expand_1toN(rz(w[which_q*3+2]), self.n_qubits, which_q))\n",
    "        #for which_q in range(0, self.n_qubits, 2):\n",
    "            #cir.append(gate_expand_1toN(rz(w[0]), self.n_qubits, which_q))\n",
    "            #cir.append(gate_expand_1toN(rz(w[1]), self.n_qubits, which_q + 1))\n",
    "            ##cir.append(gate_expand_2toN(ryy(w[2]), self.n_qubits, [which_q, which_q + 1]))\n",
    "            #cir.append(gate_expand_1toN(rx(w[2]), self.n_qubits, which_q))        \n",
    "            #cir.append(gate_expand_1toN(rx(w[3]), self.n_qubits, which_q + 1))\n",
    "            #cir.append(gate_expand_1toN(ry(w[4]), self.n_qubits, which_q))        \n",
    "            #cir.append(gate_expand_1toN(ry(w[5]), self.n_qubits, which_q + 1))\n",
    "        U = gate_sequence_product(cir, self.n_qubits)\n",
    "        return U\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        E_out = self.valueQ()\n",
    "        valueQ_out = E_out @ x @ dag(E_out)\n",
    "        return valueQ_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_query_key(queryQ_out, keyQ_out, dim_q, dim_k):\n",
    "    \"\"\"queryQ_out: type torch.Tensor\n",
    "       keyQ_out: torch.Tensor\n",
    "    \"\"\"\n",
    "    \"\"\"计算query与key的interaction score\n",
    "    \n",
    "    \"\"\"\n",
    "    out = torch.kron(queryQ_out, keyQ_out)\n",
    "    n_qubits = dim_q + dim_k\n",
    "    \n",
    "    U_list=[]\n",
    "    for t in range(dim_k):\n",
    "        U_list.append(gate_control(x_gate(),n_qubits,t,n_qubits-dim_k+t))\n",
    "    U_overall=gate_sequence_product(U_list, n_qubits)\n",
    "    \n",
    "    out=U_overall @ out @ dag(U_overall)\n",
    "    \n",
    "    quantum_score = measure(out, n_qubits)\n",
    "    \n",
    "    return quantum_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_src_value(quantum_src, valueQ_out, dim_s, dim_v):\n",
    "    \"\"\"input torch.Tensor\n",
    "    \"\"\"\n",
    "    \"\"\"计算经过attention score加权作用后的value\n",
    "    \"\"\"\n",
    "    src=quantum_src.mean()\n",
    "    phi=(src-0.5)*2*np.pi #phi=[-pi,pi]\n",
    "    \n",
    "    U_list=[]\n",
    "    ux=rx(phi*0.5)\n",
    "    uy=ry(phi*0.5)\n",
    "    uz=rz(phi)\n",
    "    for i in range(dim_v):\n",
    "        U_list.append(gate_expand_1toN(ux, dim_v, i))\n",
    "        U_list.append(gate_expand_1toN(uy, dim_v, i))\n",
    "        U_list.append(gate_expand_1toN(uz, dim_v, i))\n",
    "    \n",
    "    U_overall=gate_sequence_product(U_list,dim_v)\n",
    "    quantum_weighted_value = U_overall @ valueQ_out @ dag(U_overall)\n",
    "    \n",
    "    return quantum_weighted_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_output(qwv_list, dim):\n",
    "    \"\"\"计算weighted values的“和”（通过多个cnot门将信息融合）\n",
    "    \"\"\"\n",
    "    out = multi_kron(qwv_list)\n",
    "    n_qubits=len(qwv_list)*dim\n",
    "    U_list=[]\n",
    "    for i in range(len(qwv_list)-1):\n",
    "        for t in range(dim):\n",
    "            U_list.append(gate_control(x_gate(),n_qubits,i*dim+t,n_qubits-dim+t))\n",
    "            \n",
    "    U_overall=gate_sequence_product(U_list, n_qubits)\n",
    "    \n",
    "    out=U_overall @ out @ dag(U_overall)\n",
    "        \n",
    "    attnQ = ptrace(out, dim, n_qubits-dim)\n",
    "    return attnQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    #\"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_attention(query, key, value, mask=None, dropout=None):\n",
    "    #\"Compute 'Scaled Dot Product Attention'\"\n",
    "    query_input=query.squeeze(0)\n",
    "    key_input=key.squeeze(0)\n",
    "    value_input=value.squeeze(0)\n",
    "    #print(query_input.size(-1))\n",
    "    n_qubits=math.ceil(math.log2(query_input.size(-1)))\n",
    "    #print(n_qubits)\n",
    "    \n",
    "    qqs=[]\n",
    "    qks=[]\n",
    "    qvs=[]\n",
    "\n",
    "    for x in query_input.chunk(query_input.size(0),0):\n",
    "        #expand to 2**n_qubits length vector\n",
    "        qx=nn.ZeroPad2d((0,2**n_qubits-query_input.size(-1),0,0))(x)\n",
    "        #l2-regularization\n",
    "        if qx.dim()>2:\n",
    "            qx=qx.squeeze()\n",
    "        qinput=encoding(qx.T@qx)\n",
    "        #print(qinput)\n",
    "        init_q=init_cir_q(n_qubits=n_qubits)\n",
    "        qqs.append(init_q(qinput))\n",
    "        \n",
    "    for x in key_input.chunk(key_input.size(0),0):\n",
    "        #expand to 2**n_qubits length vector\n",
    "        qx=nn.ZeroPad2d((0,2**n_qubits-key_input.size(-1),0,0))(x)\n",
    "        #l2-regularization\n",
    "        if qx.dim()>2:\n",
    "            qx=qx.squeeze()\n",
    "        qinput=encoding(qx.T@qx)\n",
    "        #print(qinput)\n",
    "        init_k=init_cir_k(n_qubits=n_qubits)\n",
    "        qks.append(init_k(qinput))\n",
    "        \n",
    "    for x in value_input.chunk(value_input.size(0),0):\n",
    "        #expand to 2**n_qubits length vector\n",
    "        qx=nn.ZeroPad2d((0,2**n_qubits-query_input.size(-1),0,0))(x)\n",
    "        #l2-regularization\n",
    "        if qx.dim()>2:\n",
    "            qx=qx.squeeze()\n",
    "        qinput=encoding(qx.T@qx)\n",
    "        #print(qinput)\n",
    "        init_v=init_cir_v(n_qubits=n_qubits)\n",
    "        qvs.append(init_v(qinput))\n",
    "    \n",
    "    outputs=[]\n",
    "    for i in range(len(qqs)):\n",
    "        qwvs_i=[]\n",
    "        for j in range(len(qks)):\n",
    "            score_ij=cal_query_key(qqs[i],qks[j],n_qubits,n_qubits)\n",
    "            qwvs_i.append(cal_src_value(score_ij,qvs[j],n_qubits,n_qubits))\n",
    "        out_i=measure(cal_output(qwvs_i,n_qubits),n_qubits).squeeze().unsqueeze(0)\n",
    "        outputs.append(out_i)\n",
    "        #print(out_i)\n",
    "    \n",
    "    return torch.cat(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q_MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(Q_MultiHeadedAttention, self).__init__()\n",
    "        #assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        #self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linear = nn.Linear(((d_model+1)//2)*h,d_model)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"Implements Figure 2\"\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "\n",
    "        # Apply attention on all the projected vectors in batch. \n",
    "        x = q_attention(query, key, value, mask=mask, \n",
    "                                 dropout=self.dropout)\n",
    "        # multi-head\n",
    "        for i in range(self.h-1):\n",
    "            x=torch.cat((x,q_attention(query, key, value, mask=mask, dropout=self.dropout)),-1)\n",
    "        #print(x)\n",
    "        x=x.unsqueeze(0)\n",
    "        #print(x)\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1=torch.Tensor([1,0,2,0,1,0])\n",
    "input2=torch.Tensor([0,1,1,0,1,2])\n",
    "input3=torch.Tensor([0,2,1,1,1,0])\n",
    "input4=torch.Tensor([[[1,0,2,0,1,0],[0,1,1,0,1,2],[0,2,1,1,1,0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=input4.squeeze(0)\n",
    "query.size(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-162-c12b58bee8a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZeroPad2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZeroPad2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZeroPad2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "x=nn.ZeroPad2d((0,8-6,0,0))(x)\n",
    "y=nn.ZeroPad2d((0,8-6,0,0))(y)\n",
    "z=nn.ZeroPad2d((0,8-6,0,0))(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "qin1=x.T@x\n",
    "qin2=y.T@y\n",
    "qin3=z.T@z\n",
    "#qin4=w.T@w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 2., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [2., 0., 4., 0., 2., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 2., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qin1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "qinput1 = encoding(qin1)\n",
    "qinput2 = encoding(qin2)\n",
    "qinput3 = encoding(qin3)\n",
    "#qinput4 = encoding(qin4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1667+0.j, 0.0000+0.j, 0.3333+0.j, 0.0000+0.j, 0.1667+0.j, 0.0000+0.j, 0.0000+0.j,\n",
       "         0.0000+0.j],\n",
       "        [0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j,\n",
       "         0.0000+0.j],\n",
       "        [0.3333+0.j, 0.0000+0.j, 0.6667+0.j, 0.0000+0.j, 0.3333+0.j, 0.0000+0.j, 0.0000+0.j,\n",
       "         0.0000+0.j],\n",
       "        [0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j,\n",
       "         0.0000+0.j],\n",
       "        [0.1667+0.j, 0.0000+0.j, 0.3333+0.j, 0.0000+0.j, 0.1667+0.j, 0.0000+0.j, 0.0000+0.j,\n",
       "         0.0000+0.j],\n",
       "        [0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j,\n",
       "         0.0000+0.j],\n",
       "        [0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j,\n",
       "         0.0000+0.j],\n",
       "        [0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j,\n",
       "         0.0000+0.j]])"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qinput1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits=math.ceil(math.log2(qinput1.size(-1)))\n",
    "init_q=init_cir_q(n_qubits=n_qubits)\n",
    "init_k=init_cir_k(n_qubits=n_qubits)\n",
    "init_v=init_cir_v(n_qubits=n_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "qk1=init_k(qinput1)\n",
    "qq1=init_q(qinput1)\n",
    "qv1=init_v(qinput1)\n",
    "qk2=init_k(qinput2)\n",
    "qq2=init_q(qinput2)\n",
    "qv2=init_v(qinput2)\n",
    "qk3=init_k(qinput3)\n",
    "qq3=init_q(qinput3)\n",
    "qv3=init_v(qinput3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0008-2.9104e-11j,  0.0010+1.3667e-03j, -0.0117+1.2216e-03j,\n",
       "         -0.0159-1.7531e-02j,  0.0024+4.0850e-03j, -0.0037+8.8347e-03j,\n",
       "         -0.0020+6.5776e-04j, -0.0035-2.5340e-03j],\n",
       "        [ 0.0010-1.3667e-03j,  0.0034-1.1642e-10j, -0.0120+2.0448e-02j,\n",
       "         -0.0475+4.9704e-03j,  0.0095+9.2239e-04j,  0.0099+1.6621e-02j,\n",
       "         -0.0014+4.1051e-03j, -0.0083+2.6762e-03j],\n",
       "        [-0.0117-1.2216e-03j, -0.0120-2.0448e-02j,  0.1641-7.4506e-09j,\n",
       "          0.1960+2.6673e-01j, -0.0279-6.0293e-02j,  0.0647-1.1732e-01j,\n",
       "          0.0293-6.1719e-03j,  0.0451+4.0304e-02j],\n",
       "        [-0.0159+1.7531e-02j, -0.0475-4.9704e-03j,  0.1960-2.6673e-01j,\n",
       "          0.6676-2.9802e-08j, -0.1313-2.6687e-02j, -0.1134-2.4532e-01j,\n",
       "          0.0250-5.5046e-02j,  0.1193-2.5112e-02j],\n",
       "        [ 0.0024-4.0850e-03j,  0.0095-9.2239e-04j, -0.0279+6.0293e-02j,\n",
       "         -0.1313+2.6687e-02j,  0.0269-9.3132e-10j,  0.0321+4.3715e-02j,\n",
       "         -0.0027+1.1826e-02j, -0.0225+9.7091e-03j],\n",
       "        [-0.0037-8.8347e-03j,  0.0099-1.6621e-02j,  0.0647+1.1732e-01j,\n",
       "         -0.1134+2.4532e-01j,  0.0321-4.3715e-02j,  0.1094-4.0745e-10j,\n",
       "          0.0160+1.8536e-02j, -0.0110+4.8115e-02j],\n",
       "        [-0.0020-6.5776e-04j, -0.0014-4.1051e-03j,  0.0293+6.1719e-03j,\n",
       "          0.0250+5.5046e-02j, -0.0027-1.1826e-02j,  0.0160-1.8536e-02j,\n",
       "          0.0055-2.3283e-10j,  0.0065+8.8989e-03j],\n",
       "        [-0.0035+2.5340e-03j, -0.0083-2.6762e-03j,  0.0451-4.0304e-02j,\n",
       "          0.1193+2.5112e-02j, -0.0225-9.7091e-03j, -0.0110-4.8115e-02j,\n",
       "          0.0065-8.8989e-03j,  0.0223+0.0000e+00j]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qq1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1667+0.j, 0.0000+0.j, 0.3333+0.j, 0.0000+0.j, 0.1667+0.j, 0.0000+0.j, 0.0000+0.j,\n",
       "         0.0000+0.j],\n",
       "        [0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j,\n",
       "         0.0000+0.j],\n",
       "        [0.3333+0.j, 0.0000+0.j, 0.6667+0.j, 0.0000+0.j, 0.3333+0.j, 0.0000+0.j, 0.0000+0.j,\n",
       "         0.0000+0.j],\n",
       "        [0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j,\n",
       "         0.0000+0.j],\n",
       "        [0.1667+0.j, 0.0000+0.j, 0.3333+0.j, 0.0000+0.j, 0.1667+0.j, 0.0000+0.j, 0.0000+0.j,\n",
       "         0.0000+0.j],\n",
       "        [0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j,\n",
       "         0.0000+0.j],\n",
       "        [0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j,\n",
       "         0.0000+0.j],\n",
       "        [0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j,\n",
       "         0.0000+0.j]])"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qinput1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1667+0.j, 0.0000+0.j, 0.3333+0.j, 0.0000+0.j, 0.1667+0.j, 0.0000+0.j, 0.0000+0.j,\n",
       "         0.0000+0.j],\n",
       "        [0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j,\n",
       "         0.0000+0.j],\n",
       "        [0.3333+0.j, 0.0000+0.j, 0.6667+0.j, 0.0000+0.j, 0.3333+0.j, 0.0000+0.j, 0.0000+0.j,\n",
       "         0.0000+0.j],\n",
       "        [0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j,\n",
       "         0.0000+0.j],\n",
       "        [0.1667+0.j, 0.0000+0.j, 0.3333+0.j, 0.0000+0.j, 0.1667+0.j, 0.0000+0.j, 0.0000+0.j,\n",
       "         0.0000+0.j],\n",
       "        [0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j,\n",
       "         0.0000+0.j],\n",
       "        [0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j,\n",
       "         0.0000+0.j],\n",
       "        [0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j,\n",
       "         0.0000+0.j]])"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding(qinput1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "score11=cal_query_key(qq1,qk1,2,2)\n",
    "score12=cal_query_key(qq1,qk2,2,2)\n",
    "score13=cal_query_key(qq1,qk3,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score11.size(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "qwv11=cal_src_value(score11,qv1,2,2)\n",
    "qwv12=cal_src_value(score12,qv2,2,2)\n",
    "qwv13=cal_src_value(score13,qv2,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(qwv11.size(dim=0)+1)//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "output1=cal_output([qwv11,qwv12,qwv13],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.5020e-01-3.6693e-08j, -3.6089e-09+6.9849e-10j,\n",
       "         -9.3132e-10-1.6531e-08j,  8.3185e-02+1.4346e-01j],\n",
       "        [-1.1642e-09+3.0268e-09j,  6.5522e-02-4.4315e-10j,\n",
       "          1.6540e-01+1.1956e-02j, -1.7462e-10-2.2992e-09j],\n",
       "        [-1.4435e-08-7.9162e-09j,  1.6540e-01-1.1956e-02j,\n",
       "          4.2275e-01+6.8750e-09j, -2.6776e-09+1.3970e-09j],\n",
       "        [ 8.3185e-02-1.4346e-01j, -2.0373e-09-9.3132e-10j,\n",
       "         -1.2806e-09+3.0268e-09j,  6.1526e-02-4.7292e-10j]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5157],\n",
       "        [0.8730]], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure(output1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0000002-3.0733645e-08j)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.trace(output1.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000-3.0734e-08j, grad_fn=<TraceBackward>)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1.trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1.size(dim=0)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    #\"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "             / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    p_attn = F.softmax(scores, dim = -1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.6299, 0.5552, 1.6299, 0.1851, 1.0000, 0.3701],\n",
       "          [0.1312, 1.0661, 1.1312, 0.1973, 1.0000, 1.3430],\n",
       "          [0.1312, 1.5403, 1.1312, 0.6715, 1.0000, 0.3946]]]),\n",
       " tensor([[[0.6299, 0.1851, 0.1851],\n",
       "          [0.1312, 0.6715, 0.1973],\n",
       "          [0.1312, 0.1973, 0.6715]]]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention(input4,input4,input4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    #\"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_attention(query, key, value, mask=None, dropout=None):\n",
    "    #\"Compute 'Scaled Dot Product Attention'\"\n",
    "    query_input=query.squeeze(0)\n",
    "    key_input=key.squeeze(0)\n",
    "    value_input=value.squeeze(0)\n",
    "    #print(query_input.size(-1))\n",
    "    n_qubits=math.ceil(math.log2(query_input.size(-1)))\n",
    "    #print(n_qubits)\n",
    "    \n",
    "    qqs=[]\n",
    "    qks=[]\n",
    "    qvs=[]\n",
    "\n",
    "    for x in query_input.chunk(query_input.size(-2),0):\n",
    "        #expand to 2**n_qubits length vector\n",
    "        qx=nn.ZeroPad2d((0,2**n_qubits-query_input.size(-1),0,0))(x)\n",
    "        #l2-regularization\n",
    "        qinput=encoding(qx.T@qx)\n",
    "        #print(qinput)\n",
    "        init_q=init_cir_q(n_qubits=n_qubits)\n",
    "        qqs.append(init_q(qinput))\n",
    "        \n",
    "    for x in key_input.chunk(key_input.size(-2),0):\n",
    "        #expand to 2**n_qubits length vector\n",
    "        qx=nn.ZeroPad2d((0,2**n_qubits-key_input.size(-1),0,0))(x)\n",
    "        #l2-regularization\n",
    "        qinput=encoding(qx.T@qx)\n",
    "        #print(qinput)\n",
    "        init_k=init_cir_k(n_qubits=n_qubits)\n",
    "        qks.append(init_k(qinput))\n",
    "        \n",
    "    for x in value_input.chunk(value_input.size(-2),0):\n",
    "        #expand to 2**n_qubits length vector\n",
    "        qx=nn.ZeroPad2d((0,2**n_qubits-query_input.size(-1),0,0))(x)\n",
    "        #l2-regularization\n",
    "        qinput=encoding(qx.T@qx)\n",
    "        #print(qinput)\n",
    "        init_v=init_cir_v(n_qubits=n_qubits)\n",
    "        qvs.append(init_v(qinput))\n",
    "    \n",
    "    outputs=[]\n",
    "    for i in range(len(qqs)):\n",
    "        qwvs_i=[]\n",
    "        for j in range(len(qks)):\n",
    "            score_ij=cal_query_key(qqs[i],qks[j],n_qubits,n_qubits)\n",
    "            qwvs_i.append(cal_src_value(score_ij,qvs[j],n_qubits,n_qubits))\n",
    "        out_i=measure(cal_output(qwvs_i,n_qubits),n_qubits).squeeze().unsqueeze(0)\n",
    "        outputs.append(out_i)\n",
    "        #print(out_i)\n",
    "    \n",
    "    return torch.cat(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=q_attention(input4,input4,input4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=a*2\n",
    "for i in range(0):\n",
    "    b=torch.cat((b,a),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7281, 0.2631, 1.9784],\n",
       "        [0.5494, 0.2855, 1.8773],\n",
       "        [0.5202, 0.2971, 1.8487]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5783, 0.1548, 0.3597],\n",
       "        [0.5892, 0.1336, 0.2908],\n",
       "        [0.5867, 0.1376, 0.3095]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_self_attention(input4,input4,input4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        #\"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        #\"Implements Figure 2\"\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "        \n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k \n",
    "        query, key, value = \\\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "             for l, x in zip(self.linears, (query, key, value))]\n",
    "        print(query)\n",
    "        # 2) Apply attention on all the projected vectors in batch. \n",
    "        x, self.attn = attention(query, key, value, mask=mask, \n",
    "                                 dropout=self.dropout)\n",
    "        #print(x.transpose(1, 2).contiguous())\n",
    "        # 3) \"Concat\" using a view and apply a final linear. \n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "             .view(nbatches, -1, self.h * self.d_k)\n",
    "        #print(x)\n",
    "        return self.linears[-1](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.5369],\n",
      "          [ 0.4830],\n",
      "          [ 0.1692]],\n",
      "\n",
      "         [[-0.0926],\n",
      "          [-0.2298],\n",
      "          [-0.2472]],\n",
      "\n",
      "         [[-0.8817],\n",
      "          [ 0.3504],\n",
      "          [-0.2858]],\n",
      "\n",
      "         [[ 1.3838],\n",
      "          [ 0.7335],\n",
      "          [ 1.0672]],\n",
      "\n",
      "         [[ 0.4509],\n",
      "          [ 1.2404],\n",
      "          [ 0.5315]],\n",
      "\n",
      "         [[ 0.3840],\n",
      "          [ 0.5569],\n",
      "          [ 1.0117]]]], grad_fn=<TransposeBackward0>)\n",
      "tensor([[[-0.2001, -0.9336,  0.1242,  0.2809,  0.3998,  0.1934],\n",
      "         [-0.2043, -0.9525, -0.0215,  0.4122,  0.4570,  0.2638],\n",
      "         [-0.3282, -0.5282,  0.1515,  0.3077,  0.3282,  0.2255]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ma1=MultiHeadedAttention(6,6)\n",
    "tmp1=ma1(input4,input4,input4)\n",
    "print(tmp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.5654],\n",
      "          [-0.1341],\n",
      "          [ 0.3038],\n",
      "          [ 0.0000],\n",
      "          [ 0.0000],\n",
      "          [-0.0059]]],\n",
      "\n",
      "\n",
      "        [[[-0.6234],\n",
      "          [-0.5051],\n",
      "          [ 0.2206],\n",
      "          [ 0.1562],\n",
      "          [-0.0185],\n",
      "          [ 0.0046]]],\n",
      "\n",
      "\n",
      "        [[[-0.4026],\n",
      "          [-0.1340],\n",
      "          [ 0.3727],\n",
      "          [ 0.1868],\n",
      "          [ 0.0131],\n",
      "          [ 0.1126]]]], grad_fn=<TransposeBackward0>)\n",
      "tensor([[[-0.5654, -0.1341,  0.3038,  0.0000,  0.0000, -0.0059]],\n",
      "\n",
      "        [[-0.6234, -0.5051,  0.2206,  0.1562, -0.0185,  0.0046]],\n",
      "\n",
      "        [[-0.4026, -0.1340,  0.3727,  0.1868,  0.0131,  0.1126]]],\n",
      "       grad_fn=<ViewBackward>)\n"
     ]
    }
   ],
   "source": [
    "ma2=MultiHeadedAttention(6,6)\n",
    "tmp2=ma2(tmp1,tmp1,tmp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q_MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(Q_MultiHeadedAttention, self).__init__()\n",
    "        #assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linear = nn.Linear((d_model+1)//2,d_model)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"Implements Figure 2\"\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "\n",
    "        # Apply attention on all the projected vectors in batch. \n",
    "        x = q_attention(query, key, value, mask=mask, \n",
    "                                 dropout=self.dropout)\n",
    "        #print(x)\n",
    "        x=x.unsqueeze(0)\n",
    "        #print(x)\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "qma1=Q_MultiHeadedAttention(6,6)\n",
    "qma2=Q_MultiHeadedAttention(6,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input4=input4.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1015,  0.4170, -0.1365, -0.2823,  0.0775,  0.2848],\n",
       "         [-0.0490,  0.4595, -0.0639, -0.2708,  0.0932,  0.2506],\n",
       "         [-0.1068,  0.4600, -0.0612, -0.3016,  0.0705,  0.3001]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qma1(input4,input4,input4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
